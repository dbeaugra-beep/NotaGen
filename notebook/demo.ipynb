{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5cf1e7-c275-4929-9c44-ec48e26a2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch\n",
    "import random\n",
    "import bisect\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import GPT2Model, GPT2LMHeadModel, GPT2Config, LlamaModel, LlamaForCausalLM, PreTrainedModel \n",
    "from samplings import top_p_sampling, top_k_sampling, temperature_sampling\n",
    "from abctoolkit.utils import Exclaim_re, Quote_re, SquareBracket_re, Barline_regexPattern\n",
    "from abctoolkit.transpose import Note_list, Pitch_sign_list\n",
    "from abctoolkit.duration import calculate_bartext_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd2ebb-6e53-4038-af85-f9c5f02fde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations for inference\n",
    "INFERENCE_WEIGHTS_PATH = '../weights/weights_notagenx_p_size_16_p_length_1024_p_layers_20_h_size_1280.pth'               # Path to weights for inference# Folder to save output files\n",
    "TOP_K = 9                                                       # Top k for sampling\n",
    "TOP_P = 0.9                                                      # Top p for sampling\n",
    "TEMPERATURE = 1.2                                                 # Temperature for sampling\n",
    "\n",
    "# Configurations for model\n",
    "PATCH_STREAM = True                                             # Stream training / inference\n",
    "PATCH_SIZE = 16                                                # Patch Size\n",
    "PATCH_LENGTH = 1024                                             # Patch Length\n",
    "CHAR_NUM_LAYERS = 6                                             # Number of layers in the decoder\n",
    "PATCH_NUM_LAYERS = 20                                           # Number of layers in the encoder\n",
    "HIDDEN_SIZE = 1280                                               # Hidden Size\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70eb19-8b9c-4864-b711-7a0395b42c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patchilizer:\n",
    "    def __init__(self, stream=PATCH_STREAM):\n",
    "        self.stream = stream\n",
    "        self.delimiters = [\"|:\", \"::\", \":|\", \"[|\", \"||\", \"|]\", \"|\"]\n",
    "        self.regexPattern = '(' + '|'.join(map(re.escape, self.delimiters)) + ')'\n",
    "        self.bos_token_id = 1\n",
    "        self.eos_token_id = 2\n",
    "        self.special_token_id = 0\n",
    "\n",
    "    def split_bars(self, body_lines):\n",
    "        \"\"\"\n",
    "        Split a body of music into individual bars.\n",
    "        \"\"\"\n",
    "        new_bars = []\n",
    "        try:\n",
    "            for line in body_lines:\n",
    "                line_bars = re.split(self.regexPattern, line)\n",
    "                line_bars = list(filter(None, line_bars))\n",
    "                new_line_bars = []\n",
    "\n",
    "                if len(line_bars) == 1:\n",
    "                    new_line_bars = line_bars\n",
    "                else:\n",
    "                    if line_bars[0] in self.delimiters:\n",
    "                        new_line_bars = [line_bars[i] + line_bars[i + 1] for i in range(0, len(line_bars), 2)]\n",
    "                    else:\n",
    "                        new_line_bars = [line_bars[0]] + [line_bars[i] + line_bars[i + 1] for i in range(1, len(line_bars), 2)]\n",
    "                    if 'V' not in new_line_bars[-1]:\n",
    "                        new_line_bars[-2] += new_line_bars[-1]  # 吸收最后一个 小节线+\\n 的组合\n",
    "                        new_line_bars = new_line_bars[:-1]\n",
    "                new_bars += new_line_bars\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return new_bars\n",
    "\n",
    "    def split_patches(self, abc_text, patch_size=PATCH_SIZE, generate_last=False):\n",
    "        if not generate_last and len(abc_text) % patch_size != 0:\n",
    "            abc_text += chr(self.eos_token_id)\n",
    "        patches = [abc_text[i : i + patch_size] for i in range(0, len(abc_text), patch_size)]\n",
    "        return patches\n",
    "\n",
    "    def patch2chars(self, patch):\n",
    "        \"\"\"\n",
    "        Convert a patch into a bar.\n",
    "        \"\"\"\n",
    "        bytes = ''\n",
    "        for idx in patch:\n",
    "            if idx == self.eos_token_id:\n",
    "                break\n",
    "            if idx < self.eos_token_id:\n",
    "                pass\n",
    "            bytes += chr(idx)\n",
    "        return bytes\n",
    "        \n",
    "\n",
    "    def patchilize_metadata(self, metadata_lines):\n",
    "\n",
    "        metadata_patches = []\n",
    "        for line in metadata_lines:\n",
    "            metadata_patches += self.split_patches(line)\n",
    "\n",
    "        return metadata_patches\n",
    "    \n",
    "    def patchilize_tunebody(self, tunebody_lines, encode_mode='train'):\n",
    "\n",
    "        tunebody_patches = []\n",
    "        bars = self.split_bars(tunebody_lines)\n",
    "        if encode_mode == 'train':\n",
    "            for bar in bars:\n",
    "                tunebody_patches += self.split_patches(bar)\n",
    "        elif encode_mode == 'generate':\n",
    "            for bar in bars[:-1]:\n",
    "                tunebody_patches += self.split_patches(bar)\n",
    "            tunebody_patches += self.split_patches(bars[-1], generate_last=True)\n",
    "       \n",
    "        return tunebody_patches\n",
    "\n",
    "    def encode_train(self, abc_text, patch_length=PATCH_LENGTH, patch_size=PATCH_SIZE, add_special_patches=True, cut=True):\n",
    "\n",
    "        lines = abc_text.split('\\n')\n",
    "        lines = list(filter(None, lines))\n",
    "        lines = [line + '\\n' for line in lines]\n",
    "\n",
    "        tunebody_index = -1\n",
    "        for i, line in enumerate(lines):\n",
    "            if '[V:' in line:\n",
    "                tunebody_index = i\n",
    "                break\n",
    "\n",
    "        metadata_lines = lines[ : tunebody_index]\n",
    "        tunebody_lines = lines[tunebody_index : ]\n",
    "\n",
    "        if self.stream:\n",
    "            tunebody_lines = ['[r:' + str(line_index) + '/' + str(len(tunebody_lines) - line_index - 1) + ']' + line for line_index, line in\n",
    "                                enumerate(tunebody_lines)]    \n",
    "\n",
    "        metadata_patches = self.patchilize_metadata(metadata_lines)\n",
    "        tunebody_patches = self.patchilize_tunebody(tunebody_lines, encode_mode='train')\n",
    "\n",
    "        if add_special_patches:\n",
    "            bos_patch = chr(self.bos_token_id) * (patch_size - 1) + chr(self.eos_token_id)\n",
    "            eos_patch = chr(self.bos_token_id) + chr(self.eos_token_id) * (patch_size - 1)\n",
    "\n",
    "            metadata_patches = [bos_patch] + metadata_patches\n",
    "            tunebody_patches = tunebody_patches + [eos_patch]\n",
    "\n",
    "        if self.stream:\n",
    "            if len(metadata_patches) + len(tunebody_patches) > patch_length:\n",
    "                available_cut_indexes = [0] + [index + 1 for index, patch in enumerate(tunebody_patches) if '\\n' in patch]\n",
    "                line_index_for_cut_index = list(range(len(available_cut_indexes)))  \n",
    "                end_index = len(metadata_patches) + len(tunebody_patches) - patch_length\n",
    "                biggest_index = bisect.bisect_left(available_cut_indexes, end_index) \n",
    "                available_cut_indexes = available_cut_indexes[:biggest_index + 1]\n",
    "\n",
    "                if len(available_cut_indexes) == 1:\n",
    "                    choices = ['head']\n",
    "                elif len(available_cut_indexes) == 2:\n",
    "                    choices = ['head', 'tail']\n",
    "                else:\n",
    "                    choices = ['head', 'tail', 'middle']\n",
    "                choice = random.choice(choices)\n",
    "                if choice == 'head':\n",
    "                    patches = metadata_patches + tunebody_patches[0:]\n",
    "                else:\n",
    "                    if choice == 'tail':\n",
    "                        cut_index = len(available_cut_indexes) - 1\n",
    "                    else:\n",
    "                        cut_index = random.choice(range(1, len(available_cut_indexes) - 1))\n",
    "\n",
    "                    line_index = line_index_for_cut_index[cut_index] \n",
    "                    stream_tunebody_lines = tunebody_lines[line_index : ]\n",
    "                    \n",
    "                    stream_tunebody_patches = self.patchilize_tunebody(stream_tunebody_lines, encode_mode='train')\n",
    "                    if add_special_patches:\n",
    "                        stream_tunebody_patches = stream_tunebody_patches + [eos_patch]\n",
    "                    patches = metadata_patches + stream_tunebody_patches\n",
    "            else:\n",
    "                patches = metadata_patches + tunebody_patches\n",
    "        else:\n",
    "            patches = metadata_patches + tunebody_patches\n",
    "\n",
    "        if cut: \n",
    "            patches = patches[ : patch_length]\n",
    "        else:   \n",
    "            pass\n",
    "\n",
    "        # encode to ids\n",
    "        id_patches = []\n",
    "        for patch in patches:\n",
    "            id_patch = [ord(c) for c in patch] + [self.special_token_id] * (patch_size - len(patch))\n",
    "            id_patches.append(id_patch)\n",
    "\n",
    "        return id_patches\n",
    "\n",
    "    def encode_generate(self, abc_code, patch_length=PATCH_LENGTH, patch_size=PATCH_SIZE, add_special_patches=True):\n",
    "\n",
    "        lines = abc_code.split('\\n')\n",
    "        lines = list(filter(None, lines))\n",
    "    \n",
    "        tunebody_index = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith('[V:') or line.startswith('[r:'):\n",
    "                tunebody_index = i\n",
    "                break\n",
    "    \n",
    "        metadata_lines = lines[ : tunebody_index]\n",
    "        tunebody_lines = lines[tunebody_index : ]   \n",
    "    \n",
    "        metadata_lines = [line + '\\n' for line in metadata_lines]\n",
    "        if self.stream:\n",
    "            if not abc_code.endswith('\\n'):\n",
    "                tunebody_lines = [tunebody_lines[i] + '\\n' for i in range(len(tunebody_lines) - 1)] + [tunebody_lines[-1]]\n",
    "            else:\n",
    "                tunebody_lines = [tunebody_lines[i] + '\\n' for i in range(len(tunebody_lines))]\n",
    "        else:\n",
    "            tunebody_lines = [line + '\\n' for line in tunebody_lines]\n",
    "    \n",
    "        metadata_patches = self.patchilize_metadata(metadata_lines)\n",
    "        tunebody_patches = self.patchilize_tunebody(tunebody_lines, encode_mode='generate')\n",
    "    \n",
    "        if add_special_patches:\n",
    "            bos_patch = chr(self.bos_token_id) * (patch_size - 1) + chr(self.eos_token_id)\n",
    "\n",
    "            metadata_patches = [bos_patch] + metadata_patches\n",
    "    \n",
    "        patches = metadata_patches + tunebody_patches\n",
    "        patches = patches[ : patch_length]\n",
    "\n",
    "        # encode to ids\n",
    "        id_patches = []\n",
    "        for patch in patches:\n",
    "            if len(patch) < PATCH_SIZE and patch[-1] != chr(self.eos_token_id):\n",
    "                id_patch = [ord(c) for c in patch]\n",
    "            else:\n",
    "                id_patch = [ord(c) for c in patch] + [self.special_token_id] * (patch_size - len(patch))\n",
    "            id_patches.append(id_patch)\n",
    "        \n",
    "        return id_patches\n",
    "\n",
    "    def decode(self, patches):\n",
    "        \"\"\"\n",
    "        Decode patches into music.\n",
    "        \"\"\"\n",
    "        return ''.join(self.patch2chars(patch) for patch in patches)\n",
    "\n",
    "\n",
    "class PatchLevelDecoder(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    A Patch-level Decoder model for generating patch features in an auto-regressive manner. \n",
    "    It inherits PreTrainedModel from transformers.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.patch_embedding = torch.nn.Linear(PATCH_SIZE * 128, config.n_embd)\n",
    "        torch.nn.init.normal_(self.patch_embedding.weight, std=0.02)\n",
    "        self.base = GPT2Model(config)\n",
    "\n",
    "    def forward(self,\n",
    "                patches: torch.Tensor,\n",
    "                masks=None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        The forward pass of the patch-level decoder model.\n",
    "        :param patches: the patches to be encoded\n",
    "        :param masks: the masks for the patches\n",
    "        :return: the encoded patches\n",
    "        \"\"\"\n",
    "        patches = torch.nn.functional.one_hot(patches, num_classes=128).to(self.dtype)\n",
    "        patches = patches.reshape(len(patches), -1, PATCH_SIZE * (128))\n",
    "        patches = self.patch_embedding(patches.to(self.device))\n",
    "\n",
    "        if masks==None:\n",
    "            return self.base(inputs_embeds=patches)\n",
    "        else:\n",
    "            return self.base(inputs_embeds=patches,\n",
    "                             attention_mask=masks)\n",
    "\n",
    "\n",
    "class CharLevelDecoder(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    A Char-level Decoder model for generating the chars within each patch in an auto-regressive manner\n",
    "    based on the encoded patch features. It inherits PreTrainedModel from transformers.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.special_token_id = 0\n",
    "        self.bos_token_id = 1\n",
    "\n",
    "        self.base = GPT2LMHeadModel(config)\n",
    "\n",
    "    def forward(self,\n",
    "                encoded_patches: torch.Tensor,\n",
    "                target_patches: torch.Tensor):\n",
    "        \"\"\"\n",
    "        The forward pass of the char-level decoder model.\n",
    "        :param encoded_patches: the encoded patches\n",
    "        :param target_patches: the target patches\n",
    "        :return: the output of the model\n",
    "        \"\"\"\n",
    "        # preparing the labels for model training\n",
    "        target_patches = torch.cat((torch.ones_like(target_patches[:,0:1])*self.bos_token_id, target_patches), dim=1)\n",
    "        # print('target_patches shape:', target_patches.shape)\n",
    "\n",
    "        target_masks = target_patches == self.special_token_id\n",
    "        labels = target_patches.clone().masked_fill_(target_masks, -100)\n",
    "\n",
    "        # masking the labels for model training\n",
    "        target_masks = torch.ones_like(labels)\n",
    "        target_masks = target_masks.masked_fill_(labels == -100, 0)\n",
    "\n",
    "        # select patches\n",
    "        if PATCH_SAMPLING_BATCH_SIZE!=0 and PATCH_SAMPLING_BATCH_SIZE<target_patches.shape[0]:\n",
    "            indices = list(range(len(target_patches)))\n",
    "            random.shuffle(indices)\n",
    "            selected_indices = sorted(indices[:PATCH_SAMPLING_BATCH_SIZE])\n",
    "\n",
    "            target_patches = target_patches[selected_indices,:]\n",
    "            target_masks = target_masks[selected_indices,:]\n",
    "            encoded_patches = encoded_patches[selected_indices,:]\n",
    "\n",
    "        # get input embeddings\n",
    "        inputs_embeds = torch.nn.functional.embedding(target_patches, self.base.transformer.wte.weight)\n",
    "\n",
    "        # concatenate the encoded patches with the input embeddings\n",
    "        inputs_embeds = torch.cat((encoded_patches.unsqueeze(1), inputs_embeds[:,1:,:]), dim=1)\n",
    "\n",
    "        output = self.base(inputs_embeds=inputs_embeds, \n",
    "                         attention_mask=target_masks,\n",
    "                         labels=labels)\n",
    "                         # output_hidden_states=True=True)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def generate(self,\n",
    "                 encoded_patch: torch.Tensor,   # [hidden_size]\n",
    "                 tokens: torch.Tensor): # [1]\n",
    "        \"\"\"\n",
    "        The generate function for generating a patch based on the encoded patch and already generated tokens.\n",
    "        :param encoded_patch: the encoded patch\n",
    "        :param tokens: already generated tokens in the patch\n",
    "        :return: the probability distribution of next token\n",
    "        \"\"\"\n",
    "        encoded_patch = encoded_patch.reshape(1, 1, -1) # [1, 1, hidden_size]\n",
    "        tokens = tokens.reshape(1, -1)\n",
    "\n",
    "        # Get input embeddings\n",
    "        tokens = torch.nn.functional.embedding(tokens, self.base.transformer.wte.weight)\n",
    "\n",
    "        # Concatenate the encoded patch with the input embeddings\n",
    "        tokens = torch.cat((encoded_patch, tokens[:,1:,:]), dim=1)\n",
    "        \n",
    "        # Get output from model\n",
    "        outputs = self.base(inputs_embeds=tokens)\n",
    "        \n",
    "        # Get probabilities of next token\n",
    "        probs = torch.nn.functional.softmax(outputs.logits.squeeze(0)[-1], dim=-1)\n",
    "\n",
    "        return probs\n",
    "\n",
    "class NotaGenLMHeadModel(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    NotaGen is a language model with a hierarchical structure.\n",
    "    It includes a patch-level decoder and a char-level decoder.\n",
    "    The patch-level decoder is used to generate patch features in an auto-regressive manner.\n",
    "    The char-level decoder is used to generate the chars within each patch in an auto-regressive manner.\n",
    "    It inherits PreTrainedModel from transformers.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_config, decoder_config):\n",
    "        super().__init__(encoder_config)\n",
    "        self.special_token_id = 0\n",
    "        self.bos_token_id = 1\n",
    "        self.eos_token_id = 2\n",
    "        self.patch_level_decoder = PatchLevelDecoder(encoder_config)\n",
    "        self.char_level_decoder = CharLevelDecoder(decoder_config)\n",
    "\n",
    "    def forward(self,\n",
    "                patches: torch.Tensor,\n",
    "                masks: torch.Tensor):\n",
    "        \"\"\"\n",
    "        The forward pass of the bGPT model.\n",
    "        :param patches: the patches to be encoded\n",
    "        :param masks: the masks for the patches\n",
    "        :return: the decoded patches\n",
    "        \"\"\"\n",
    "        patches = patches.reshape(len(patches), -1, PATCH_SIZE)\n",
    "        encoded_patches = self.patch_level_decoder(patches, masks)[\"last_hidden_state\"]\n",
    "        \n",
    "        left_shift_masks = masks * (masks.flip(1).cumsum(1).flip(1) > 1)\n",
    "        masks[:, 0] = 0\n",
    "        \n",
    "        encoded_patches = encoded_patches[left_shift_masks == 1]\n",
    "        patches = patches[masks == 1]        \n",
    "\n",
    "        return self.char_level_decoder(encoded_patches, patches)\n",
    "        \n",
    "    def generate(self,\n",
    "                 patches: torch.Tensor,\n",
    "                 top_k=0,\n",
    "                 top_p=1,\n",
    "                 temperature=1.0):\n",
    "        \"\"\"\n",
    "        The generate function for generating patches based on patches.\n",
    "        :param patches: the patches to be encoded\n",
    "        :param top_k: the top k for sampling\n",
    "        :param top_p: the top p for sampling\n",
    "        :param temperature: the temperature for sampling\n",
    "        :return: the generated patches\n",
    "        \"\"\"\n",
    "        if patches.shape[-1] % PATCH_SIZE != 0:\n",
    "            tokens = patches[:,:,-(patches.shape[-1]%PATCH_SIZE):].squeeze(0, 1)\n",
    "            tokens = torch.cat((torch.tensor([self.bos_token_id], device=self.device), tokens), dim=-1)\n",
    "            patches = patches[:,:,:-(patches.shape[-1]%PATCH_SIZE)]\n",
    "        else:\n",
    "            tokens =  torch.tensor([self.bos_token_id], device=self.device)\n",
    "\n",
    "        patches = patches.reshape(len(patches), -1, PATCH_SIZE) # [bs, seq, patch_size]\n",
    "        encoded_patches = self.patch_level_decoder(patches)[\"last_hidden_state\"]    # [bs, seq, hidden_size]\n",
    "        generated_patch = []            \n",
    "\n",
    "        while True:\n",
    "            prob = self.char_level_decoder.generate(encoded_patches[0][-1], tokens).cpu().detach().numpy()  # [128]\n",
    "            prob = top_k_sampling(prob, top_k=top_k, return_probs=True) # [128]\n",
    "            prob = top_p_sampling(prob, top_p=top_p, return_probs=True) # [128]\n",
    "            token = temperature_sampling(prob, temperature=temperature) # int\n",
    "            char = chr(token)\n",
    "            generated_patch.append(token)\n",
    "\n",
    "            if len(tokens) >= PATCH_SIZE:# or token == self.eos_token_id:\n",
    "                break\n",
    "            else:\n",
    "                tokens = torch.cat((tokens, torch.tensor([token], device=self.device)), dim=0)\n",
    "        \n",
    "        return generated_patch\n",
    "\n",
    "def clean_to_abc(raw_text, unreduce=True, output_path='output.abc'):\n",
    "    # Remove [r:x/y] tags\n",
    "    cleaned = re.sub(r'\\[r:\\d+/\\d+\\]', '', raw_text)\n",
    "\n",
    "    # Add required ABC headers\n",
    "    lines = cleaned.strip().splitlines()\n",
    "    header_inserted = False\n",
    "    abc_lines = []\n",
    "    for line in lines:\n",
    "        if not header_inserted and line.startswith('%%score'):\n",
    "            abc_lines.insert(0, 'T:Generated\\n')\n",
    "            abc_lines.insert(0, 'X:1\\n')\n",
    "            header_inserted = True\n",
    "        abc_lines.append(line if line.endswith('\\n') else line + '\\n')\n",
    "\n",
    "    # Optional: fill missing rests\n",
    "    if unreduce:\n",
    "        try:\n",
    "            abc_lines = rest_unreduce(abc_lines)\n",
    "        except Exception as e:\n",
    "            print(\"Unreduce failed:\", e)\n",
    "\n",
    "    # Save to .abc file\n",
    "    Path(output_path).write_text(''.join(abc_lines), encoding='utf-8')\n",
    "    print(f\"Saved cleaned ABC to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d126533-a9a1-48a5-9b1b-be6da37a55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Note_list = Note_list + ['z', 'x']\n",
    "\n",
    "patchilizer = Patchilizer()\n",
    "\n",
    "patch_config = GPT2Config(num_hidden_layers=PATCH_NUM_LAYERS,\n",
    "                          max_length=PATCH_LENGTH,\n",
    "                          max_position_embeddings=PATCH_LENGTH,\n",
    "                          n_embd=HIDDEN_SIZE,\n",
    "                          num_attention_heads=HIDDEN_SIZE // 64,\n",
    "                          vocab_size=1)\n",
    "byte_config = GPT2Config(num_hidden_layers=CHAR_NUM_LAYERS,\n",
    "                         max_length=PATCH_SIZE + 1,\n",
    "                         max_position_embeddings=PATCH_SIZE + 1,\n",
    "                         hidden_size=HIDDEN_SIZE,\n",
    "                         num_attention_heads=HIDDEN_SIZE // 64,\n",
    "                         vocab_size=128)\n",
    "\n",
    "model = NotaGenLMHeadModel(encoder_config=patch_config, decoder_config=byte_config).to(device)\n",
    "\n",
    "def prepare_model_for_kbit_training(model, use_gradient_checkpointing=True):\n",
    "    \"\"\"\n",
    "    Prepare model for k-bit training.\n",
    "    Features include:\n",
    "    1. Convert model to mixed precision (FP16).\n",
    "    2. Disable unnecessary gradient computations.\n",
    "    3. Enable gradient checkpointing (optional).\n",
    "    \"\"\"\n",
    "    # Convert model to mixed precision\n",
    "    model = model.to(dtype=torch.float16)\n",
    "\n",
    "    # Disable gradients for embedding layers\n",
    "    for param in model.parameters():\n",
    "        if param.dtype == torch.float32:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Enable gradient checkpointing\n",
    "    if use_gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = prepare_model_for_kbit_training(\n",
    "    model,\n",
    "    use_gradient_checkpointing=False  \n",
    ")\n",
    "\n",
    "print(\"Parameter Number: \" + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "checkpoint = torch.load(INFERENCE_WEIGHTS_PATH, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def complete_brackets(s):\n",
    "    stack = []\n",
    "    bracket_map = {'{': '}', '[': ']', '(': ')'}\n",
    "    \n",
    "    # Iterate through each character, handle bracket matching\n",
    "    for char in s:\n",
    "        if char in bracket_map:\n",
    "            stack.append(char)\n",
    "        elif char in bracket_map.values():\n",
    "            # Find the corresponding left bracket\n",
    "            for key, value in bracket_map.items():\n",
    "                if value == char:\n",
    "                    if stack and stack[-1] == key:\n",
    "                        stack.pop()\n",
    "                    break  # Found matching right bracket, process next character\n",
    "    \n",
    "    # Complete missing right brackets (in reverse order of remaining left brackets in stack)\n",
    "    completion = ''.join(bracket_map[c] for c in reversed(stack))\n",
    "    return s + completion\n",
    "\n",
    "\n",
    "def rest_unreduce(abc_lines):\n",
    "\n",
    "    tunebody_index = None\n",
    "    for i in range(len(abc_lines)):\n",
    "        if abc_lines[i].startswith('%%score'):\n",
    "            abc_lines[i] = complete_brackets(abc_lines[i])\n",
    "        if '[V:' in abc_lines[i]:\n",
    "            tunebody_index = i\n",
    "            break\n",
    "\n",
    "    metadata_lines = abc_lines[: tunebody_index]\n",
    "    tunebody_lines = abc_lines[tunebody_index:]\n",
    "\n",
    "    part_symbol_list = []\n",
    "    voice_group_list = []\n",
    "    for line in metadata_lines:\n",
    "        if line.startswith('%%score'):\n",
    "            for round_bracket_match in re.findall(r'\\((.*?)\\)', line):\n",
    "                voice_group_list.append(round_bracket_match.split())\n",
    "            existed_voices = [item for sublist in voice_group_list for item in sublist]\n",
    "        if line.startswith('V:'):\n",
    "            symbol = line.split()[0]\n",
    "            part_symbol_list.append(symbol)\n",
    "            if symbol[2:] not in existed_voices:\n",
    "                voice_group_list.append([symbol[2:]])\n",
    "    z_symbol_list = []  # voices that use z as rest\n",
    "    x_symbol_list = []  # voices that use x as rest\n",
    "    for voice_group in voice_group_list:\n",
    "        z_symbol_list.append('V:' + voice_group[0])\n",
    "        for j in range(1, len(voice_group)):\n",
    "            x_symbol_list.append('V:' + voice_group[j])\n",
    "\n",
    "    part_symbol_list.sort(key=lambda x: int(x[2:]))\n",
    "\n",
    "    unreduced_tunebody_lines = []\n",
    "\n",
    "    for i, line in enumerate(tunebody_lines):\n",
    "        unreduced_line = ''\n",
    "\n",
    "        line = re.sub(r'^\\[r:[^\\]]*\\]', '', line)\n",
    "\n",
    "        pattern = r'\\[V:(\\d+)\\](.*?)(?=\\[V:|$)'\n",
    "        matches = re.findall(pattern, line)\n",
    "\n",
    "        line_bar_dict = {}\n",
    "        for match in matches:\n",
    "            key = f'V:{match[0]}'\n",
    "            value = match[1]\n",
    "            line_bar_dict[key] = value\n",
    "\n",
    "        # calculate duration and collect barline\n",
    "        dur_dict = {}  \n",
    "        for symbol, bartext in line_bar_dict.items():\n",
    "            right_barline = ''.join(re.split(Barline_regexPattern, bartext)[-2:])\n",
    "            bartext = bartext[:-len(right_barline)]\n",
    "            try:\n",
    "                bar_dur = calculate_bartext_duration(bartext)\n",
    "            except:\n",
    "                bar_dur = None\n",
    "            if bar_dur is not None:\n",
    "                if bar_dur not in dur_dict.keys():\n",
    "                    dur_dict[bar_dur] = 1\n",
    "                else:\n",
    "                    dur_dict[bar_dur] += 1\n",
    "\n",
    "        try:\n",
    "            ref_dur = max(dur_dict, key=dur_dict.get)\n",
    "        except:\n",
    "            pass    # use last ref_dur\n",
    "\n",
    "        if i == 0:\n",
    "            prefix_left_barline = line.split('[V:')[0]\n",
    "        else:\n",
    "            prefix_left_barline = ''\n",
    "\n",
    "        for symbol in part_symbol_list:\n",
    "            if symbol in line_bar_dict.keys():\n",
    "                symbol_bartext = line_bar_dict[symbol]\n",
    "            else:\n",
    "                if symbol in z_symbol_list:\n",
    "                    symbol_bartext = prefix_left_barline + 'z' + str(ref_dur) + right_barline\n",
    "                elif symbol in x_symbol_list:\n",
    "                    symbol_bartext = prefix_left_barline + 'x' + str(ref_dur) + right_barline\n",
    "            unreduced_line += '[' + symbol + ']' + symbol_bartext\n",
    "\n",
    "        unreduced_tunebody_lines.append(unreduced_line + '\\n')\n",
    "\n",
    "    unreduced_lines = metadata_lines + unreduced_tunebody_lines\n",
    "\n",
    "    return unreduced_lines\n",
    "\n",
    "\n",
    "def inference_patch(period, composer, instrumentation):\n",
    "\n",
    "    prompt_lines=[\n",
    "    '%' + period + '\\n',\n",
    "    '%' + composer + '\\n',\n",
    "    '%' + instrumentation + '\\n']\n",
    "\n",
    "    while True:\n",
    "\n",
    "        failure_flag = False\n",
    "\n",
    "        bos_patch = [patchilizer.bos_token_id] * (PATCH_SIZE - 1) + [patchilizer.eos_token_id]\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        prompt_patches = patchilizer.patchilize_metadata(prompt_lines)\n",
    "        byte_list = list(''.join(prompt_lines))\n",
    "        context_tunebody_byte_list = []\n",
    "        metadata_byte_list = []\n",
    "\n",
    "        print(''.join(byte_list), end='')\n",
    "\n",
    "        prompt_patches = [[ord(c) for c in patch] + [patchilizer.special_token_id] * (PATCH_SIZE - len(patch)) for patch\n",
    "                          in prompt_patches]\n",
    "        prompt_patches.insert(0, bos_patch)\n",
    "\n",
    "        input_patches = torch.tensor(prompt_patches, device=device).reshape(1, -1)\n",
    "\n",
    "        end_flag = False\n",
    "        cut_index = None\n",
    "\n",
    "        tunebody_flag = False\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            \n",
    "            while True:\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    predicted_patch = model.generate(input_patches.unsqueeze(0),\n",
    "                                                    top_k=TOP_K,\n",
    "                                                    top_p=TOP_P,\n",
    "                                                    temperature=TEMPERATURE)\n",
    "                if not tunebody_flag and patchilizer.decode([predicted_patch]).startswith('[r:'):  # 初次进入tunebody，必须以[r:0/开头\n",
    "                    tunebody_flag = True\n",
    "                    r0_patch = torch.tensor([ord(c) for c in '[r:0/']).unsqueeze(0).to(device)\n",
    "                    temp_input_patches = torch.concat([input_patches, r0_patch], axis=-1)\n",
    "                    predicted_patch = model.generate(temp_input_patches.unsqueeze(0),\n",
    "                                                    top_k=TOP_K,\n",
    "                                                    top_p=TOP_P,\n",
    "                                                    temperature=TEMPERATURE)\n",
    "                    predicted_patch = [ord(c) for c in '[r:0/'] + predicted_patch\n",
    "                if predicted_patch[0] == patchilizer.bos_token_id and predicted_patch[1] == patchilizer.eos_token_id:\n",
    "                    end_flag = True\n",
    "                    break\n",
    "                next_patch = patchilizer.decode([predicted_patch])\n",
    "\n",
    "                for char in next_patch:\n",
    "                    byte_list.append(char)\n",
    "                    if tunebody_flag:\n",
    "                        context_tunebody_byte_list.append(char)\n",
    "                    else:\n",
    "                        metadata_byte_list.append(char)\n",
    "                    print(char, end='')\n",
    "\n",
    "                patch_end_flag = False\n",
    "                for j in range(len(predicted_patch)):\n",
    "                    if patch_end_flag:\n",
    "                        predicted_patch[j] = patchilizer.special_token_id\n",
    "                    if predicted_patch[j] == patchilizer.eos_token_id:\n",
    "                        patch_end_flag = True\n",
    "\n",
    "                predicted_patch = torch.tensor([predicted_patch], device=device)  # (1, 16)\n",
    "                input_patches = torch.cat([input_patches, predicted_patch], dim=1)  # (1, 16 * patch_len)\n",
    "\n",
    "                if len(byte_list) > 102400:\n",
    "                    failure_flag = True\n",
    "                    break\n",
    "                if time.time() - start_time > 10 * 60: \n",
    "                    failure_flag = True\n",
    "                    break\n",
    "\n",
    "                if input_patches.shape[1] >= PATCH_LENGTH * PATCH_SIZE and not end_flag:\n",
    "                    print('Stream generating...')\n",
    "\n",
    "                    metadata = ''.join(metadata_byte_list)\n",
    "                    context_tunebody = ''.join(context_tunebody_byte_list)\n",
    "\n",
    "                    if '\\n' not in context_tunebody:\n",
    "                        break   # Generated content is all metadata, abandon\n",
    "\n",
    "                    context_tunebody_liness = context_tunebody.split('\\n')\n",
    "                    if not context_tunebody.endswith('\\n'):\n",
    "                        context_tunebody_liness = [context_tunebody_liness[i] + '\\n' for i in range(len(context_tunebody_liness) - 1)] + [context_tunebody_liness[-1]]\n",
    "                    else:\n",
    "                        context_tunebody_liness = [context_tunebody_liness[i] + '\\n' for i in range(len(context_tunebody_liness))]\n",
    "\n",
    "                    cut_index = len(context_tunebody_liness) // 2\n",
    "                    abc_code_slice = metadata + ''.join(context_tunebody_liness[-cut_index:])\n",
    "\n",
    "                    input_patches = patchilizer.encode_generate(abc_code_slice)\n",
    "\n",
    "                    input_patches = [item for sublist in input_patches for item in sublist]\n",
    "                    input_patches = torch.tensor([input_patches], device=device)\n",
    "                    input_patches = input_patches.reshape(1, -1)\n",
    "\n",
    "                    context_tunebody_byte_list = list(''.join(context_tunebody_lines[-cut_index:]))\n",
    "\n",
    "            if not failure_flag:\n",
    "                abc_text = ''.join(byte_list)\n",
    "\n",
    "                # unreduce\n",
    "                abc_lines = abc_text.split('\\n')\n",
    "                abc_lines = list(filter(None, abc_lines))\n",
    "                abc_lines = [line + '\\n' for line in abc_lines]\n",
    "                try:\n",
    "                    unreduced_abc_lines = rest_unreduce(abc_lines)\n",
    "                except:\n",
    "                    failure_flag = True\n",
    "                    pass\n",
    "                else:\n",
    "                    unreduced_abc_lines = [line for line in unreduced_abc_lines if not(line.startswith('%') and not line.startswith('%%'))]\n",
    "                    unreduced_abc_lines = ['X:1\\n'] + unreduced_abc_lines\n",
    "                    unreduced_abc_text = ''.join(unreduced_abc_lines)\n",
    "                    return unreduced_abc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c4420-533b-43cc-80ca-b2c94cd4be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_patch('Classical', 'Beethoven, Ludwig van', 'Art Song')\n",
    "\n",
    "abc_lines = result.splitlines()\n",
    "abc_lines = [line + '\\n' for line in abc_lines if line.strip()]  # Add newlines and remove empty lines\n",
    "\n",
    "abc_lines = rest_unreduce(abc_lines)\n",
    "\n",
    "with open(\"output.abc\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(abc_lines)\n",
    "\n",
    "!python abc2xml.py -o . output.abc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
